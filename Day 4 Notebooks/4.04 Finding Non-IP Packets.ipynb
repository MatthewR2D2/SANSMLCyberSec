{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagenumbering{gobble}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Non-IP Packets - A Lesson in False Correlations\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this experiment, we are going to create a very simple model to solve a very simple problem... And fail. You will use your existing knowledge to build the network and learn a bit about parsing packet capture files along the way.\n",
    "\n",
    "## Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "\n",
    " * Read packet captures\n",
    " * Build a training data set from packets\n",
    " * Build a model to attempt to distinguish IP from non-IP packets on a network\n",
    " \n",
    "## Estimated Time: 30 minutes\n",
    "\n",
    "# Obtaining the Data\n",
    "\n",
    "The data for this lab is stored in the `../data/Day 4/` directory relative to this notebook.  Within that directory are two packet captures: `ip-notip.cap` and `test_ip_notip.cap`.\n",
    "\n",
    "# <img src=\"../images/task.png\" width=20 height=20> Task 4.1\n",
    "\n",
    "Please use the following cell to:\n",
    " * Import the *numpy* library with the typical `np` alias\n",
    " * Import *tensorflow* as `tf`\n",
    " * Import the `models` and `layers` packages from `tensorflow.keras`\n",
    " * Import the `PcapReader` and `hexdump` class/method from `scapy.all`\n",
    " \n",
    "**Note:** You may receive a warning regarding deprecated aspects of the `ipsec.py` file from within Scapy.  These can be safely ignored and are expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 09:58:38.278140: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-27 09:58:38.278168: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-27 09:58:38.278203: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-27 09:58:38.286806: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from scapy.all import PcapReader, hexdump\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are about to read in packet capture data.  These capture files are stored in *pcap* format, which is used by tools such as Wireshark, Scapy, Snort, Firepower, tcpdump, Zeek, etc.  Within these captures are a variety of packets, some of which are IPv4, some of which are not.  All of these packets have been sent using Ethernet.\n",
    "\n",
    "An Ethernet frame header consists of a six byte destination MAC address, a six byte source MAC address, and a two byte ethertype.  It is this ethertype value that should be used to distinguish between IPv4 packets and other types of data.  IPv4 will have the hexadecimal value `0x0800` in these two bytes located at offsets 12 and 13 from the start of the frame header.\n",
    "\n",
    "While this is a trivial problem, certainly simpler than our spam classifier, we will try to solve it in an interesting way.  If we had subject matter expertise with regard to network packets, then we could tell our network to use only those two bytes.  However, if we were going to take this tack, we may as well use something like a decision tree rather than a neural network to solve the problem.  Our experiment, though, is slightly different.\n",
    "\n",
    "What if we don't know which bytes indicate that a packet is IP?  Is it possible for a neural network to work out a way to figure it out for us?  This is the problem we're going to solve.\n",
    "\n",
    "## Preparing the Data\n",
    "The first step, as usual, is to preprocess the data into a useable format.  We will leverage the Scapy library to read the packets in and building a data set for training.  In the matrix that is created, each row will be a packet and the row vector within that row will be all of the bytes that make up the 14 byte Ethernet header (the first fourteen bytes present).\n",
    "\n",
    "# <img src=\"../images/task.png\" width=20 height=20> Task 4.2\n",
    "\n",
    "The `PcapReader()` class exposes the packets from a packet capture to us as though it is an interable file.  For example, we can write something like this:\n",
    "\n",
    "```\n",
    "with PcapReader(\"pcap_file\") as packets:\n",
    "    for packet in packets:\n",
    "    ...\n",
    "```\n",
    "\n",
    "In the cell that follows:\n",
    "\n",
    "  * Use the `PcapReader()` class to iterate over the list of packets from the `ip-notip.cap` file\n",
    "  * The file can be found in `../data/Day 4`\n",
    "  * The bytes are unsigned 8 bit values; create a variable to hold `np.dtype('uint8')` as a type named *byte*\n",
    "  * Assign the first fourteen bytes of each packet to a numpy array of type *byte*.\n",
    "  * Use the `hexdump()` function to print out the resulting array for the first ten packets\n",
    "  * Use the Python `bytes()` function to treat the data as indexable list of bytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000  01 00 5E 00 00 09 00 50 56 86 27 F6 08 00        ..^....PV.'...\n",
      "0000  00 50 56 86 27 F6 00 50 56 86 01 A9 08 00        .PV.'..PV.....\n",
      "0000  00 50 56 86 01 A9 00 50 56 86 27 F6 08 00        .PV....PV.'...\n",
      "0000  00 50 56 86 27 F6 00 50 56 86 01 A9 08 00        .PV.'..PV.....\n",
      "0000  00 50 56 86 01 A9 00 50 56 86 27 F6 08 00        .PV....PV.'...\n",
      "0000  00 50 56 86 27 F6 00 50 56 86 01 A9 08 00        .PV.'..PV.....\n",
      "0000  00 50 56 86 01 A9 00 50 56 86 27 F6 08 00        .PV....PV.'...\n",
      "0000  00 50 56 86 27 F6 00 50 56 86 01 A9 08 00        .PV.'..PV.....\n",
      "0000  00 50 56 86 01 A9 00 50 56 86 27 F6 08 00        .PV....PV.'...\n",
      "0000  01 00 5E 00 00 09 00 50 56 86 D4 C3 08 00        ..^....PV.....\n"
     ]
    }
   ],
   "source": [
    "byte = np.dtype('uint8')\n",
    "\n",
    "# Let's load in some packet data.\n",
    "with PcapReader(\"../data/Day 4/ip-notip.cap\") as packets:\n",
    "    for i, packet in enumerate(packets):\n",
    "        parray = np.frombuffer(bytes(packet), dtype=byte, offset=0, count=14)\n",
    "        if i < 10:\n",
    "            hexdump(parray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've managed to load a pcap in using PcapReader and we can turn the Ethernet header into a row vector containing all of the bytes in the header!  Looking at the output above, you can see that the first ten rows of data all end with the values `08 00` indicating that the encapsulated packet is an IPv4 packet.\n",
    "\n",
    "# <img src=\"../images/task.png\" width=20 height=20> Task 4.3\n",
    "\n",
    "Load all of the data into an array named `x_data`.  At the same time, create a label array named `y_labels` that simply has a zero or a one to indicate whether each respective packet is IP or not.  To make this decision, you will need to evaluate each packet as you read it, checking offsets 12 and 13 for the values `08` and `00`.\n",
    "\n",
    "When you complete this task, print one or two values from the `x_data` array and verify that the label in `y_data` is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label for item offset 10 is 1\n",
      "The bytes from offset 10 are:\n",
      "0000  00 50 56 86 27 F6 00 50 56 86 01 A9 08 00        .PV.'..PV.....\n",
      "After converting to numpy arrays, the data has shape (50000, 14) and the labels have shape (50000,)\n"
     ]
    }
   ],
   "source": [
    "x_data = list()\n",
    "y_labels = list()\n",
    "with PcapReader(\"../data/Day 4/ip-notip.cap\") as packets:\n",
    "    for packet in packets:\n",
    "        linkLayer = np.frombuffer(bytes(packet), dtype=byte, offset=0, count=14)\n",
    "        x_data.append(linkLayer)\n",
    "        if linkLayer[12]==0x08 and linkLayer[13]==0x00:\n",
    "            y_labels.append(1)\n",
    "        else:\n",
    "            y_labels.append(0)\n",
    "        \n",
    "print(f\"The label for item offset 10 is {y_labels[10]}\")\n",
    "print(f\"The bytes from offset 10 are:\")\n",
    "hexdump(x_data[10])\n",
    "x_data = np.array(x_data)\n",
    "y_labels = np.array(y_labels)\n",
    "print(f\"After converting to numpy arrays, the data has shape {x_data.shape} and the labels have shape {y_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network\n",
    "\n",
    "# <img src=\"../images/task.png\" width=20 height=20> Task 4.4\n",
    "\n",
    "Now that we've beaten our data into submission, it's time to build and train our network.  Please build a sequential model with three dense layers.  The layers should have 64, 16, and 1 neuron respectively.  Use the `relu` activation function for the first two and `sigmoid` for the output layer.\n",
    "\n",
    "Configure the optimizer to use `rmsprop`.  Set the `loss` value appropriately for the type of problem we are solving.  Use the `tf.random.set_seed(42)` call to ensure that all of our networks perform identically.  Train your model for four epochs using a `batch_size` of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 10:00:05.676918: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.682385: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.682674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.684439: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.684731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.685012: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.765904: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.766070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.766215: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-27 10:00:05.766352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5501 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2023-12-27 10:00:07.032931: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3a402e66f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-27 10:00:07.032993: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1060, Compute Capability 6.1\n",
      "2023-12-27 10:00:07.036917: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-27 10:00:07.048564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-12-27 10:00:07.111796: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 6s 3ms/step - loss: 0.0769 - accuracy: 0.9910\n",
      "Epoch 2/4\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0251 - accuracy: 0.9940\n",
      "Epoch 3/4\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0252 - accuracy: 0.9941\n",
      "Epoch 4/4\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0188 - accuracy: 0.9956\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(14,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "training_history = model.fit(x_data, y_labels, epochs=4, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model\n",
    "\n",
    "This all seems very promising!  The training went really quickly and it's reporting an accuracy of 99.82%!  The next step is to try this against some real data and see what it can do.  To do so, we'll continue to manipulate the model here within this notebook.\n",
    "\n",
    "# <img src=\"../images/task.png\" width=20 height=20> Task 4.5\n",
    "\n",
    "Repeat the above required steps to load in a test dataset from the packet capture `test_ip_notip.cap` from the same location.  Use this dataset to run predictions and then print out the hexdump of each, the prediction generated, and whether or not the prediction is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  01 00 5E 00 00 09 00 50 56 86 A7 48 08 00        ..^....PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 A7 48 00 50 56 86 7C 39 08 00        .PV..H.PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 1 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 A7 48 08 00        .PV.|9.PV..H..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 7C 39 08 06        .......PV.|9..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 52 73 08 06        .PV.|9.PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 A7 48 08 06        .......PV..H..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 A7 48 08 06        .......PV..H..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 7C 39 08 06        .......PV.|9..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 0            **** MISMATCH!\n",
      "0000  00 50 56 86 7C 39 00 50 56 86 2F 17 08 06        .PV.|9.PV./...\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 A7 48 08 06        .......PV..H..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  00 50 56 86 7C 39 00 50 56 86 52 73 08 06        .PV.|9.PV.Rs..\n",
      "---------------------\n",
      "Prediction: 1\tGround Truth: 0            **** MISMATCH!\n",
      "0000  00 50 56 86 52 73 00 50 56 86 7C 39 08 06        .PV.Rs.PV.|9..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n",
      "Prediction: 0\tGround Truth: 0 \n",
      "0000  FF FF FF FF FF FF 00 50 56 86 52 73 08 06        .......PV.Rs..\n",
      "---------------------\n"
     ]
    }
   ],
   "source": [
    "x_test = list()\n",
    "y_test = list()\n",
    "with PcapReader(\"../data/Day 4/test_ip_notip.cap\") as packets:\n",
    "    for packet in packets:\n",
    "        linkLayer = np.frombuffer(bytes(packet), dtype=byte, offset=0, count=14)\n",
    "        x_test.append(linkLayer)\n",
    "        if linkLayer[12]==0x08 and linkLayer[13]==0x00:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "            \n",
    "x_test = np.array(x_test)\n",
    "\n",
    "# The next step is to make predictions!\n",
    "predictions = model.predict(x_test)\n",
    "for i in range(0,predictions.size):\n",
    "    predicted = 1 if predictions[i] >= 0.5 else 0\n",
    "    print(f'Prediction: { predicted }\\tGround Truth: {y_test[i]} {\"           **** MISMATCH!\" if predicted != y_test[i] else \"\"}')\n",
    "    hexdump(x_test[i])\n",
    "    print(\"---------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "So how did the model do?  Pretty well!  But... there's a problem.  The majority of the predictions are correct, but there are a few non-IP packets that are marked as being IP!  (You can tell because the last two values in the hexdump are `08 06`.) What went wrong?  \n",
    "\n",
    "Think about this question and how you could correct this problem.  We know from the problem statement at the beginning that we are including lots of irrelevant features to our model.  A simple and direct solution would be to change the model so that it *only* looks at the last two bytes.  If we made that change, this model would train to 100% after just a handful of examples.\n",
    "\n",
    "Still, *why* is the network arriving at the wrong answer some of the time?  In this case, the network has made a *false correlation*.  We can point at how we've modeled the features as the cause, but we can also point at the training data.  In our case, it is a reasonable guess that the packets in our training data set have some particular characteristics.  Most notably, the majority (if not all) of the training examples are either IP or ARP.  Since ARP packets are *broadcast packets* (meaning that they are sent to all hosts) at least half of the time, this strongly biases our model.  It incorrectly identifies the broadcast addresses (the series of `FF FF FF FF FF FF` in many of the non-IP packets) as the indicator that the packet isn't IP!  This results in incorrect predictions because some of our test data has non-IP packets that are *not* broadcast.\n",
    "\n",
    "Ultimately, the details about the packets are not what matter.  The big picture outcome is that by including extraneous features or by poorly selecting training data we can easily end up with a model that makes false correlations.\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "While this lab was relatively simple compared to the other problems we've solved, there are some important takeaways:\n",
    "\n",
    " * We have successfully applied what we have learned about deep learning to a completely different problem\n",
    " * We can read and process packet captures as bytes easily\n",
    " * Feature selection can have a big impact on how well a model generalizes\n",
    " * Training data can have an equally large impact on how well a model generalizes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
